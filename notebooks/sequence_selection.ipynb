{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "from sklearn import preprocessing\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from botorch.utils.multi_objective import pareto\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setting up the MRL scaler  \n",
    "The Optimus5Prime provided in the directory is trained using a normalized MRL values, and therefore predict normalized values. The scaler loaded here will transform the noramlized values back to the actual MRL values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.read_csv(os.path.join(\"./data/GSM3130435_egfp_unmod_1_processed.tsv\"), sep=\"\\t\")[\"rl\"]\n",
    "scaler = preprocessing.StandardScaler().fit(np.array(label_data).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_obj_to_real(df_tmp, column_name, obj_name):\n",
    "    if obj_name == \"AGC content [%]\":\n",
    "        obj_val = np.array(df_tmp[column_name])\n",
    "        seq_length = len(df_tmp[\"cand_seq\"].iloc[0])\n",
    "        obj_val = (seq_length - obj_val) / seq_length * 100\n",
    "    elif obj_name == \"MRL\":\n",
    "        obj_val = np.array(df_tmp[column_name])\n",
    "        obj_val = scaler.inverse_transform(-obj_val.reshape(-1,1)).flatten()\n",
    "    elif obj_name == \"G4 score\":\n",
    "        obj_val = - np.array(df_tmp[column_name])\n",
    "    elif obj_name == \"in vitro stability\":\n",
    "        obj_val = - np.array(df_tmp[column_name])\n",
    "    return obj_val\n",
    "\n",
    "def format_to_rna(tmp_array):\n",
    "    for i, seq in enumerate(tmp_array):\n",
    "        tmp_array[i] = seq.replace(\"T\", \"U\")\n",
    "    return tmp_array\n",
    "    \n",
    "def format_init(df_init):\n",
    "    df_init = df_init.rename(\n",
    "        columns={\n",
    "            \"sequence\":\"cand_seq\",\n",
    "            \"nonU_cotent\":\"obj_val_0\",\n",
    "            \"mrl\":\"obj_val_1\",\n",
    "            \"G4\":\"obj_val_2\",\n",
    "            \"degradation\":\"obj_val_3\"\n",
    "        }\n",
    "    )\n",
    "    df_init[\"round_idx\"] = [0,]*len(df_init)\n",
    "    df_init[\"cand_uuid\"] = [\"\",]*len(df_init)\n",
    "    df_init[\"cand_ancestor\"] = [\"\",]*len(df_init)\n",
    "    # df_init = df_init.reindex(columns=[\"round_idx\",\"cand_uuid\",\"cand_ancestor\",\"cand_seq\",\"obj_val_0\",\"obj_val_1\",\"obj_val_2\",\"obj_val_3\"])\n",
    "    return df_init\n",
    "\n",
    "# assume all objectives are to be maximized\n",
    "def pareto_ranking(df_all, df_pareto, obj_names):\n",
    "    rank_scores = []\n",
    "    for i in range(len(df_pareto)):\n",
    "        df_tmp = df_all.copy()\n",
    "        for tmp_obj in obj_names:\n",
    "            df_tmp = df_tmp[df_tmp[tmp_obj]<=df_pareto[tmp_obj].iloc[i]]\n",
    "        rank_scores.append(len(df_tmp)+1)\n",
    "    df_pareto[\"score_pareto_ranking\"] = rank_scores\n",
    "    df_pareto = df_pareto.sort_values(by=\"score_pareto_ranking\", ascending=False)\n",
    "    return df_pareto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_pareto_fronts(model_flg, data_dir, obj_columns, obj_names, save_dir, save_file):\n",
    "    df_all = pd.DataFrame([], columns=obj_names)\n",
    "    df_pareto = pd.DataFrame()\n",
    "    if model_flg == \"init\":\n",
    "        for init_num in [2,3,4]:\n",
    "            initset = f\"initset{init_num}\"\n",
    "            init_file = f\"../cache_dir/Sample2019_unmod1_{initset}_numsample512_ConstructSample2019EGFP.csv\"\n",
    "            df_init = format_init(pd.read_csv(init_file))\n",
    "\n",
    "            df_save = pd.DataFrame([], columns=obj_names)\n",
    "            new_points = None\n",
    "            for obj_column, obj_name in zip(obj_columns, obj_names):\n",
    "                tmp_obj = convert_obj_to_real(df_init, obj_column, obj_name)\n",
    "                if new_points is None:\n",
    "                    new_points = np.expand_dims(tmp_obj, -1)\n",
    "                else:\n",
    "                    new_points = np.concatenate([new_points, np.expand_dims(tmp_obj, -1)], -1)\n",
    "            df_save[\"sequence\"] = format_to_rna(np.array(df_init[\"cand_seq\"]))\n",
    "            df_save[\"initset\"] = initset\n",
    "            df_save[obj_names] = new_points\n",
    "            if len(df_all) == 0:\n",
    "                df_all = df_save.copy()\n",
    "            else:\n",
    "                df_all = pd.concat([df_all, df_save], axis=0)\n",
    "            \n",
    "            all_seqs = df_save[[\"sequence\", \"initset\"]].values\n",
    "            pareto_mask = pareto.is_non_dominated(torch.tensor(new_points))\n",
    "            pareto_idx = np.argsort(new_points[pareto_mask][:,0])\n",
    "            pareto_front = np.array(all_seqs[pareto_mask][pareto_idx]) # np.expand_dims(, -1)\n",
    "            pareto_front = np.concatenate([pareto_front, new_points[pareto_mask][pareto_idx]], axis=-1)\n",
    "            df_pareto_save = pd.DataFrame(pareto_front, columns=[\"sequence\", \"initset\"]+obj_names)\n",
    "            if len(df_pareto) == 0:\n",
    "                df_pareto = df_pareto_save.copy()\n",
    "            else:\n",
    "                df_pareto = pd.concat([df_pareto, df_pareto_save], axis=0)\n",
    "    else:\n",
    "        for tmp_file in os.listdir(data_dir):\n",
    "            if model_flg in tmp_file:\n",
    "                initset = re.search(\"initset[0-9]+\", tmp_file).group()\n",
    "                init_file = f\"../cache_dir/Sample2019_unmod1_{initset}_numsample512_ConstructSample2019EGFP.csv\"\n",
    "                df_init = format_init(pd.read_csv(init_file))\n",
    "\n",
    "                df_tmp = pd.read_csv(os.path.join(data_dir, tmp_file))\n",
    "                df_tmp = pd.concat([df_init, df_tmp], axis=0)\n",
    "                df_tmp = df_tmp.drop_duplicates(subset=[\"cand_seq\"], keep=\"first\")\n",
    "                df_tmp = df_tmp.reset_index(drop=True)\n",
    "\n",
    "                df_save = pd.DataFrame([], columns=obj_names)\n",
    "                new_points = None\n",
    "                for obj_column, obj_name in zip(obj_columns, obj_names):\n",
    "                    tmp_obj = convert_obj_to_real(df_tmp, obj_column, obj_name)\n",
    "                    if new_points is None:\n",
    "                        new_points = np.expand_dims(tmp_obj, -1)\n",
    "                    else:\n",
    "                        new_points = np.concatenate([new_points, np.expand_dims(tmp_obj, -1)], -1)\n",
    "                df_save[\"sequence\"] = format_to_rna(np.array(df_tmp[\"cand_seq\"]))\n",
    "                df_save[\"initset\"] = initset\n",
    "                df_save[obj_names] = new_points\n",
    "                if len(df_all) == 0:\n",
    "                    df_all = df_save.copy()\n",
    "                else:\n",
    "                    df_all = pd.concat([df_all, df_save], axis=0)\n",
    "                \n",
    "                all_seqs = df_save[[\"sequence\", \"initset\"]].values\n",
    "                pareto_mask = pareto.is_non_dominated(torch.tensor(new_points))\n",
    "                pareto_idx = np.argsort(new_points[pareto_mask][:,0])\n",
    "                pareto_front = np.array(all_seqs[pareto_mask][pareto_idx]) # np.expand_dims(, -1)\n",
    "                pareto_front = np.concatenate([pareto_front, new_points[pareto_mask][pareto_idx]], axis=-1)\n",
    "                df_pareto_save = pd.DataFrame(pareto_front, columns=[\"sequence\", \"initset\"]+obj_names)\n",
    "                if len(df_pareto) == 0:\n",
    "                    df_pareto = df_pareto_save.copy()\n",
    "                else:\n",
    "                    df_pareto = pd.concat([df_pareto, df_pareto_save], axis=0)\n",
    "\n",
    "    df_all = df_all.drop_duplicates(subset=[\"sequence\"], keep=\"first\")\n",
    "    df_all = df_all.reset_index(drop=True)\n",
    "    print(f\"\\tNumber of generated sequences: {len(df_all)}\")\n",
    "    df_pareto = pareto_ranking(df_all, df_pareto, obj_names)\n",
    "    print(f\"\\tNumber of non-dominated sequences: {len(df_pareto)}\")\n",
    "    save_path = os.path.join(save_dir, save_file)\n",
    "    print(f\"\\tSaving file to {save_path}\")\n",
    "    df_pareto.to_csv(save_path, index=False)\n",
    "\n",
    "def cluster_seqs(save_dir, save_file, usearch_path):\n",
    "    csv_path = os.path.join(save_dir, save_file)\n",
    "    file_prefix = save_file.split(\".\")[0]\n",
    "    fasta_path = os.path.join(save_dir, file_prefix + \".fasta\")\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    tmp_out_file = os.path.join(fasta_path)\n",
    "    fd = open(tmp_out_file, \"w\")\n",
    "    seq_list = []\n",
    "    for i in range(len(df)):\n",
    "        # desc = \"seq{}_from_{}\".format(i+1, df[\"run\"].iloc[i])\n",
    "        seq_list.append(SeqRecord(Seq(df[\"sequence\"].iloc[i]), id=str(i)))\n",
    "    SeqIO.write(seq_list, fd, \"fasta\")\n",
    "    fd.close()\n",
    "\n",
    "    min_sequence_identity = 60\n",
    "    cluster_path = os.path.join(save_dir, \"cluster{}\".format(min_sequence_identity))\n",
    "    options = {\n",
    "        \"cluster_fast\": fasta_path,\n",
    "        \"id\": min_sequence_identity / 100,\n",
    "        \"clusters\": cluster_path + \"/c_\",\n",
    "    }\n",
    "\n",
    "    if \"clusters\" in options.keys():\n",
    "        if os.path.exists(cluster_path):\n",
    "            shutil.rmtree(cluster_path)\n",
    "        os.makedirs(cluster_path)\n",
    "\n",
    "    cmd = usearch_path\n",
    "    for k, v in options.items():\n",
    "        cmd = cmd + \" -{} {}\".format(k, v)\n",
    "    print(f\"\\tExecuting UCLUST:\\n\\t{cmd}\\n\")\n",
    "    os.system(cmd)\n",
    "    return cluster_path\n",
    "\n",
    "def assign_clusters(save_dir, save_file, cluster_path):\n",
    "    print(\"\\n\\tassigning a cluster to each seqeunce\")\n",
    "    csv_path = os.path.join(save_dir, save_file)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    cluster_dirs = os.listdir(cluster_path)\n",
    "    cluster_list = [\"\"] * len(df)\n",
    "    for cluster in cluster_dirs:\n",
    "        fasta_sequences = SeqIO.parse(open(os.path.join(cluster_path, cluster)),\"fasta\")\n",
    "        for fasta in fasta_sequences:\n",
    "            sequence = str(fasta.seq)\n",
    "            idx = df.query(\"sequence == \"{}\"\".format(sequence)).index[0]\n",
    "            cluster_list[idx] = cluster\n",
    "    df[\"cluster\"] = cluster_list\n",
    "    print(f\"\\tsaving file to {csv_path}\")\n",
    "    df.to_csv(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Ranking generated sequences\n",
    "Retrieving generated sequences during LaMBO trainings.  \n",
    "For each corresponding run, the table of generated sequences should be uploaded to your wandb workspace as \"task_mugd_cnn/candidates\" or you can find them under your local wandb directory such as `./wandb/RUNTITLE/files/media/table/task_mugd_cnn/candidates_ID.table.json`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing init\n",
      "\tNumber of generated sequences: 1530\n",
      "\tNumber of non-dominated sequences: 112\n",
      "\tSaving file to ./tmp/tmp.csv\n",
      "\tExecuting UCLUST:\n",
      "\t/home/keisuke-yamada/tools/usearch11.0.667_i86linux32 -cluster_fast ./tmp/tmp.fasta -id 0.6 -clusters ./tmp/cluster60/c_\n",
      "\n",
      "usearch v11.0.667_i86linux32, 4.0Gb RAM (330Gb total), 16 cores\n",
      "(C) Copyright 2013-18 Robert C. Edgar, all rights reserved.\n",
      "https://drive5.com/usearch\n",
      "\n",
      "License: personal use only\n",
      "\n",
      "\n",
      "\tassigning a cluster to each seqeunce\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:00 41Mb    100.0% Reading ./tmp/tmp.fasta\n",
      "00:00 7.1Mb  CPU has 16 cores, defaulting to 10 threads\n",
      "00:00 315Mb   100.0% DF\n",
      "00:00 319Mb  112 seqs, 112 uniques, 112 singletons (100.0%)\n",
      "00:00 319Mb  Min size 1, median 1, max 1, avg 1.00\n",
      "00:00 322Mb   100.0% DB\n",
      "00:00 328Mb   100.0% 112 clusters, max size 1, avg 1.0\n",
      "00:00 328Mb   100.0% Writing clusters                 \n",
      "                                     \n",
      "      Seqs  112\n",
      "  Clusters  112\n",
      "  Max size  1\n",
      "  Avg size  1.0\n",
      "  Min size  1\n",
      "Singletons  112, 100.0% of seqs, 100.0% of clusters\n",
      "   Max mem  328Mb\n",
      "      Time  1.00s\n",
      "Throughput  112.0 seqs/sec.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tsaving file to ./tmp/tmp.csv\n",
      "Saving selected seqs to init_selected.csv\n",
      "Processing DNABERT\n",
      "\tNumber of generated sequences: 7533\n",
      "\tNumber of non-dominated sequences: 394\n",
      "\tSaving file to ./tmp/tmp.csv\n",
      "\tExecuting UCLUST:\n",
      "\t/home/keisuke-yamada/tools/usearch11.0.667_i86linux32 -cluster_fast ./tmp/tmp.fasta -id 0.6 -clusters ./tmp/cluster60/c_\n",
      "\n",
      "usearch v11.0.667_i86linux32, 4.0Gb RAM (330Gb total), 16 cores\n",
      "(C) Copyright 2013-18 Robert C. Edgar, all rights reserved.\n",
      "https://drive5.com/usearch\n",
      "\n",
      "License: personal use only\n",
      "\n",
      "\n",
      "\tassigning a cluster to each seqeunce\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:00 41Mb    100.0% Reading ./tmp/tmp.fasta\n",
      "00:00 7.1Mb  CPU has 16 cores, defaulting to 10 threads\n",
      "00:00 316Mb   100.0% DF\n",
      "00:00 319Mb  394 seqs, 394 uniques, 394 singletons (100.0%)\n",
      "00:00 319Mb  Min size 1, median 1, max 1, avg 1.00\n",
      "00:00 322Mb   100.0% DB\n",
      "00:00 328Mb   100.0% 47 clusters, max size 45, avg 8.4\n",
      "00:00 328Mb   100.0% Writing clusters                 \n",
      "                                     \n",
      "      Seqs  394\n",
      "  Clusters  47\n",
      "  Max size  45\n",
      "  Avg size  8.4\n",
      "  Min size  1\n",
      "Singletons  6, 1.5% of seqs, 12.8% of clusters\n",
      "   Max mem  328Mb\n",
      "      Time  1.00s\n",
      "Throughput  394.0 seqs/sec.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tsaving file to ./tmp/tmp.csv\n",
      "Saving selected seqs to DNABERT_selected.csv\n",
      "Processing BERT\n",
      "\tNumber of generated sequences: 13664\n",
      "\tNumber of non-dominated sequences: 873\n",
      "\tSaving file to ./tmp/tmp.csv\n",
      "\tExecuting UCLUST:\n",
      "\t/home/keisuke-yamada/tools/usearch11.0.667_i86linux32 -cluster_fast ./tmp/tmp.fasta -id 0.6 -clusters ./tmp/cluster60/c_\n",
      "\n",
      "usearch v11.0.667_i86linux32, 4.0Gb RAM (330Gb total), 16 cores\n",
      "(C) Copyright 2013-18 Robert C. Edgar, all rights reserved.\n",
      "https://drive5.com/usearch\n",
      "\n",
      "License: personal use only\n",
      "\n",
      "\n",
      "\tassigning a cluster to each seqeunce\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:00 41Mb    100.0% Reading ./tmp/tmp.fasta\n",
      "00:00 7.1Mb  CPU has 16 cores, defaulting to 10 threads\n",
      "00:00 320Mb   100.0% DF\n",
      "00:01 319Mb  873 seqs, 873 uniques, 873 singletons (100.0%)\n",
      "00:01 319Mb  Min size 1, median 1, max 1, avg 1.00\n",
      "00:01 322Mb   100.0% DB\n",
      "00:01 328Mb   100.0% 103 clusters, max size 70, avg 8.5\n",
      "00:01 328Mb   100.0% Writing clusters                  \n",
      "                                     \n",
      "      Seqs  873\n",
      "  Clusters  103\n",
      "  Max size  70\n",
      "  Avg size  8.5\n",
      "  Min size  1\n",
      "Singletons  10, 1.1% of seqs, 9.7% of clusters\n",
      "   Max mem  328Mb\n",
      "      Time  1.00s\n",
      "Throughput  873.0 seqs/sec.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tsaving file to ./tmp/tmp.csv\n",
      "Saving selected seqs to BERT_selected.csv\n",
      "Processing CNN\n",
      "\tNumber of generated sequences: 7528\n",
      "\tNumber of non-dominated sequences: 524\n",
      "\tSaving file to ./tmp/tmp.csv\n",
      "\tExecuting UCLUST:\n",
      "\t/home/keisuke-yamada/tools/usearch11.0.667_i86linux32 -cluster_fast ./tmp/tmp.fasta -id 0.6 -clusters ./tmp/cluster60/c_\n",
      "\n",
      "usearch v11.0.667_i86linux32, 4.0Gb RAM (330Gb total), 16 cores\n",
      "(C) Copyright 2013-18 Robert C. Edgar, all rights reserved.\n",
      "https://drive5.com/usearch\n",
      "\n",
      "License: personal use only\n",
      "\n",
      "\n",
      "\tassigning a cluster to each seqeunce\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:00 41Mb    100.0% Reading ./tmp/tmp.fasta\n",
      "00:00 7.1Mb  CPU has 16 cores, defaulting to 10 threads\n",
      "00:00 316Mb   100.0% DF\n",
      "00:00 319Mb  524 seqs, 524 uniques, 524 singletons (100.0%)\n",
      "00:00 319Mb  Min size 1, median 1, max 1, avg 1.00\n",
      "00:00 322Mb   100.0% DB\n",
      "00:00 328Mb   100.0% 36 clusters, max size 73, avg 14.6\n",
      "00:00 328Mb   100.0% Writing clusters                  \n",
      "                                     \n",
      "      Seqs  524\n",
      "  Clusters  36\n",
      "  Max size  73\n",
      "  Avg size  14.6\n",
      "  Min size  1\n",
      "Singletons  3, 0.6% of seqs, 8.3% of clusters\n",
      "   Max mem  328Mb\n",
      "      Time  1.00s\n",
      "Throughput  524.0 seqs/sec.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tsaving file to ./tmp/tmp.csv\n",
      "Saving selected seqs to CNN_selected.csv\n"
     ]
    }
   ],
   "source": [
    "models = [\"init\", \"CNN\", \"BERT\", \"DNABERT\", ]\n",
    "data_dir = \"./generated_seqs\"\n",
    "# f\"../cache_dir/Sample2019_unmod1_{initset_flg}_numsample512_ConstructSample2019EGFP.csv\"\n",
    "obj_columns = [\"obj_val_0\",\"obj_val_1\",\"obj_val_2\",\"obj_val_3\"]\n",
    "obj_names = [\"AGC content [%]\", \"MRL\", \"G4 score\", \"in vitro stability\"]\n",
    "usearch_path = \"/home/keisuke-yamada/tools/usearch11.0.667_i86linux32\"\n",
    "\n",
    "if not os.path.exists(\"./tmp\"):\n",
    "    os.makedirs(\"./tmp\")\n",
    "\n",
    "for model_flg in models:\n",
    "    print(f\"Processing {model_flg}\")\n",
    "    collect_pareto_fronts(model_flg, data_dir, obj_columns, obj_names, save_dir=\"./tmp\", save_file=\"tmp.csv\")\n",
    "    cluster_path = cluster_seqs(save_dir=\"./tmp\", save_file=\"tmp.csv\", usearch_path=usearch_path)\n",
    "    assign_clusters(save_dir=\"./tmp\", save_file=\"tmp.csv\", cluster_path=cluster_path)\n",
    "    df = pd.read_csv(\"./tmp/tmp.csv\")\n",
    "    df = df.sort_values(by=\"score_pareto_ranking\", ascending=False)\n",
    "    df = df.drop_duplicates(subset=[\"cluster\"], keep=\"first\")\n",
    "    print(f\"Saving selected seqs to {model_flg}_selected.csv\")\n",
    "    df.to_csv(f\"{model_flg}_rank.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Selecting candidates for wet-lab experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>initset</th>\n",
       "      <th>AGC content [%]</th>\n",
       "      <th>MRL</th>\n",
       "      <th>G4 score</th>\n",
       "      <th>in vitro stability</th>\n",
       "      <th>score_pareto_ranking</th>\n",
       "      <th>cluster</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGUUCACCAAAGAAGGAAAUUCACAGCUGCAAAUGAGCACGGCAAA...</td>\n",
       "      <td>initset4</td>\n",
       "      <td>88.0</td>\n",
       "      <td>7.441092</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.425877</td>\n",
       "      <td>1244</td>\n",
       "      <td>c_43</td>\n",
       "      <td>init</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCCAAAGCCAAUACGAAGCAACAGUUGGAUCCUAAGUCCUCUGAAA...</td>\n",
       "      <td>initset2</td>\n",
       "      <td>84.0</td>\n",
       "      <td>7.580640</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.422809</td>\n",
       "      <td>1117</td>\n",
       "      <td>c_0</td>\n",
       "      <td>init</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCCACCAUUUCGACCAAACGAACAUCAACCAAACAAGACACUGUGU...</td>\n",
       "      <td>initset4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>7.158506</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.424855</td>\n",
       "      <td>1021</td>\n",
       "      <td>c_1</td>\n",
       "      <td>init</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CACUAGGAAGAGAAGAGAAAAGAAAAUACACAAAUACAAAGGAGCA...</td>\n",
       "      <td>initset3</td>\n",
       "      <td>94.0</td>\n",
       "      <td>7.895419</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.417397</td>\n",
       "      <td>6525</td>\n",
       "      <td>c_0</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAGAGAGAAAGCACACAGGAAGACACAAGGACAAGACGCAGAGGAU...</td>\n",
       "      <td>initset3</td>\n",
       "      <td>98.0</td>\n",
       "      <td>7.654273</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.422110</td>\n",
       "      <td>4087</td>\n",
       "      <td>c_3</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAGACAGCAGUAGAGAGACAGAUCCUAACCCAGAAACACAAACAUC...</td>\n",
       "      <td>initset4</td>\n",
       "      <td>88.0</td>\n",
       "      <td>7.803958</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.421110</td>\n",
       "      <td>3840</td>\n",
       "      <td>c_1</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAAAAAAAGAAAAAGAACCAACAGUUGGACCCCAAAUCCUCUGCAA...</td>\n",
       "      <td>initset2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>7.715036</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.421037</td>\n",
       "      <td>3786</td>\n",
       "      <td>c_5</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CACAAGGAGUAGAACAAAUUCACACAAGCGAAAGAGUACACUUCAC...</td>\n",
       "      <td>initset3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>7.946205</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.418353</td>\n",
       "      <td>3639</td>\n",
       "      <td>c_11</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAGAGGAAAAAAAAAAACAACGAAGAAAAAAAAGAGAGAAAGAGAA...</td>\n",
       "      <td>initset3</td>\n",
       "      <td>98.0</td>\n",
       "      <td>7.906004</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.412688</td>\n",
       "      <td>10967</td>\n",
       "      <td>c_0</td>\n",
       "      <td>BERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAGAAAGAAAAAAAAAACAAAGAAGAAAACAAAGAGACAAAGAAAA...</td>\n",
       "      <td>initset3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.819129</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.410769</td>\n",
       "      <td>10337</td>\n",
       "      <td>c_2</td>\n",
       "      <td>BERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAGAGACAAAGAGAGAAAAGGGACCAAGAAAACUAAGACGAACAA...</td>\n",
       "      <td>initset2</td>\n",
       "      <td>98.0</td>\n",
       "      <td>7.766171</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.418115</td>\n",
       "      <td>10091</td>\n",
       "      <td>c_69</td>\n",
       "      <td>BERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GAAAAACACAGAGAAACAAUAGUAGAGGAGCCACAUACAGAACACA...</td>\n",
       "      <td>initset4</td>\n",
       "      <td>94.0</td>\n",
       "      <td>7.911500</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.419680</td>\n",
       "      <td>10063</td>\n",
       "      <td>c_3</td>\n",
       "      <td>BERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAGAGAAACACAAAACAGAGAAACACAAGACAAAGACGAACAGAAG...</td>\n",
       "      <td>initset3</td>\n",
       "      <td>98.0</td>\n",
       "      <td>7.886711</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.418002</td>\n",
       "      <td>10053</td>\n",
       "      <td>c_1</td>\n",
       "      <td>BERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAGAGGAAAAAAAAAAACAACGAAGAAAAAAAAGAGAGAAAGAGAA...</td>\n",
       "      <td>initset3</td>\n",
       "      <td>98.0</td>\n",
       "      <td>7.906004</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.412688</td>\n",
       "      <td>5759</td>\n",
       "      <td>c_0</td>\n",
       "      <td>DNABERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAGAAAGAAAAAAAAAACAAAGAAGAAAACAAAGAGACAAAGAAAA...</td>\n",
       "      <td>initset3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.819129</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.410769</td>\n",
       "      <td>5301</td>\n",
       "      <td>c_2</td>\n",
       "      <td>DNABERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GAAAAACACAGAGAAACAAUAGUAGAGGAGCCACAUACAGAACACA...</td>\n",
       "      <td>initset4</td>\n",
       "      <td>94.0</td>\n",
       "      <td>7.911500</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.419680</td>\n",
       "      <td>5054</td>\n",
       "      <td>c_3</td>\n",
       "      <td>DNABERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAGAGAAACACAAAACAGAGAAACACAAGACAAAGACGAACAGAAG...</td>\n",
       "      <td>initset3</td>\n",
       "      <td>98.0</td>\n",
       "      <td>7.886711</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.418002</td>\n",
       "      <td>5042</td>\n",
       "      <td>c_1</td>\n",
       "      <td>DNABERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAGAGACAAAGAGAGAAAAGGGACCAAGAAAACUAAGACGAACAA...</td>\n",
       "      <td>initset2</td>\n",
       "      <td>98.0</td>\n",
       "      <td>7.766171</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.418115</td>\n",
       "      <td>4964</td>\n",
       "      <td>c_32</td>\n",
       "      <td>DNABERT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence   initset  \\\n",
       "0  AGUUCACCAAAGAAGGAAAUUCACAGCUGCAAAUGAGCACGGCAAA...  initset4   \n",
       "1  CCCAAAGCCAAUACGAAGCAACAGUUGGAUCCUAAGUCCUCUGAAA...  initset2   \n",
       "2  CCCACCAUUUCGACCAAACGAACAUCAACCAAACAAGACACUGUGU...  initset4   \n",
       "0  CACUAGGAAGAGAAGAGAAAAGAAAAUACACAAAUACAAAGGAGCA...  initset3   \n",
       "1  CAGAGAGAAAGCACACAGGAAGACACAAGGACAAGACGCAGAGGAU...  initset3   \n",
       "2  CAGACAGCAGUAGAGAGACAGAUCCUAACCCAGAAACACAAACAUC...  initset4   \n",
       "3  CAAAAAAAGAAAAAGAACCAACAGUUGGACCCCAAAUCCUCUGCAA...  initset2   \n",
       "4  CACAAGGAGUAGAACAAAUUCACACAAGCGAAAGAGUACACUUCAC...  initset3   \n",
       "0  AAGAGGAAAAAAAAAAACAACGAAGAAAAAAAAGAGAGAAAGAGAA...  initset3   \n",
       "1  AAGAAAGAAAAAAAAAACAAAGAAGAAAACAAAGAGACAAAGAAAA...  initset3   \n",
       "2  AAAGAGACAAAGAGAGAAAAGGGACCAAGAAAACUAAGACGAACAA...  initset2   \n",
       "3  GAAAAACACAGAGAAACAAUAGUAGAGGAGCCACAUACAGAACACA...  initset4   \n",
       "4  AAGAGAAACACAAAACAGAGAAACACAAGACAAAGACGAACAGAAG...  initset3   \n",
       "0  AAGAGGAAAAAAAAAAACAACGAAGAAAAAAAAGAGAGAAAGAGAA...  initset3   \n",
       "1  AAGAAAGAAAAAAAAAACAAAGAAGAAAACAAAGAGACAAAGAAAA...  initset3   \n",
       "2  GAAAAACACAGAGAAACAAUAGUAGAGGAGCCACAUACAGAACACA...  initset4   \n",
       "3  AAGAGAAACACAAAACAGAGAAACACAAGACAAAGACGAACAGAAG...  initset3   \n",
       "4  AAAGAGACAAAGAGAGAAAAGGGACCAAGAAAACUAAGACGAACAA...  initset2   \n",
       "\n",
       "   AGC content [%]       MRL  G4 score  in vitro stability  \\\n",
       "0             88.0  7.441092      -0.2           -0.425877   \n",
       "1             84.0  7.580640      -0.3           -0.422809   \n",
       "2             86.0  7.158506      -0.3           -0.424855   \n",
       "0             94.0  7.895419      -0.1           -0.417397   \n",
       "1             98.0  7.654273      -0.2           -0.422110   \n",
       "2             88.0  7.803958      -0.2           -0.421110   \n",
       "3             88.0  7.715036      -0.1           -0.421037   \n",
       "4             84.0  7.946205      -0.2           -0.418353   \n",
       "0             98.0  7.906004      -0.2           -0.412688   \n",
       "1            100.0  7.819129      -0.2           -0.410769   \n",
       "2             98.0  7.766171      -0.1           -0.418115   \n",
       "3             94.0  7.911500      -0.1           -0.419680   \n",
       "4             98.0  7.886711      -0.2           -0.418002   \n",
       "0             98.0  7.906004      -0.2           -0.412688   \n",
       "1            100.0  7.819129      -0.2           -0.410769   \n",
       "2             94.0  7.911500      -0.1           -0.419680   \n",
       "3             98.0  7.886711      -0.2           -0.418002   \n",
       "4             98.0  7.766171      -0.1           -0.418115   \n",
       "\n",
       "   score_pareto_ranking cluster    model  \n",
       "0                  1244    c_43     init  \n",
       "1                  1117     c_0     init  \n",
       "2                  1021     c_1     init  \n",
       "0                  6525     c_0      CNN  \n",
       "1                  4087     c_3      CNN  \n",
       "2                  3840     c_1      CNN  \n",
       "3                  3786     c_5      CNN  \n",
       "4                  3639    c_11      CNN  \n",
       "0                 10967     c_0     BERT  \n",
       "1                 10337     c_2     BERT  \n",
       "2                 10091    c_69     BERT  \n",
       "3                 10063     c_3     BERT  \n",
       "4                 10053     c_1     BERT  \n",
       "0                  5759     c_0  DNABERT  \n",
       "1                  5301     c_2  DNABERT  \n",
       "2                  5054     c_3  DNABERT  \n",
       "3                  5042     c_1  DNABERT  \n",
       "4                  4964    c_32  DNABERT  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [\"init\", \"CNN\", \"BERT\", \"DNABERT\", ]\n",
    "df_cand = pd.DataFrame()\n",
    "for i in models:\n",
    "    df = pd.read_csv(\"{}_rank.csv\".format(i))\n",
    "    df = df.sort_values(by=\"score_pareto_ranking\", ascending=False)\n",
    "    df = df.drop_duplicates(subset=[\"cluster\"], keep=\"first\")\n",
    "    df[\"model\"] = i\n",
    "    if i==\"init\":\n",
    "        df_cand = pd.concat([df_cand, df.iloc[:3,:]])\n",
    "    else:\n",
    "        df_cand = pd.concat([df_cand, df.iloc[:5,:]])\n",
    "df_cand.to_csv(\"candidates.csv\", index=False)\n",
    "df_cand"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
